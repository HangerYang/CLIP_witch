{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "check = [\"training/194568_1604124183\",\n",
    "\"training/291861_1881017768\",\n",
    "\"training/530248_935229304\",\n",
    "\"training/722800_1549665606\",\n",
    "\"training/1081938_3142694740\",\n",
    "\"training/1194525_921340984\",\n",
    "\"training/1244871_41621993\",\n",
    "\"training/1296633_2473957678\",\n",
    "\"training/1783609_2620113026\", \n",
    "\"training/2416314_4259351717\", \n",
    "\"training/2852354_909904571\",\n",
    "\"training/2937089_3840145690\"]\n",
    "df1 = pd.read_csv('cc/Train-GCC-training.tsv', sep='\\t', names=[\"caption\",\"url\"])\n",
    "df2 = pd.read_csv('cc/downloaded_training_report.tsv', sep='\\t', names=[\"file\",\"folder\",\"mimetype\",\"size\",\"status\",\"url\"])\n",
    "df2 = df2.dropna(subset=[\"size\"])\n",
    "df2 = df2[df2[\"status\"] == 200]\n",
    "df2 = df2[df2[\"size\"] < 13000000]\n",
    "df2 = df2[df2[\"size\"] > 0]\n",
    "df2 = df2[df2['mimetype'].str.contains('image')]\n",
    "df2 = df2[~df2['file'].isin(check)]\n",
    "df2=df2.drop_duplicates(subset=[\"url\"])\n",
    "df1=df1.drop_duplicates(subset=[\"url\"])\n",
    "df3 = pd.merge(df2, df1, on=\"url\")[[\"caption\", \"file\"]]\n",
    "total_k = df3.values.tolist()\n",
    "# final_k = np.array(total_k)\n",
    "\n",
    "cifar10 = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "size = 2000\n",
    "final_list = []\n",
    "for i in cifar10:\n",
    "    partial_dataset = np.array([[*x, i] for x in total_k if re.search(r'\\b' + i + r'\\b', x[0])])\n",
    "    idx = np.random.choice(len(partial_dataset), size)\n",
    "    final_list.append(partial_dataset[idx])\n",
    "final_list = np.vstack(final_list)\n",
    "\n",
    "\n",
    "\n",
    "poisoners = ['dog', 'bed', 'truck']\n",
    "defenders = ['cat', 'bee', 'deer']\n",
    "num = 1\n",
    "poison_per_category = 1\n",
    "poison_range = [num]\n",
    "total_poison = len(poison_range) * poison_per_category\n",
    "total_pairs = np.array([]).reshape(0,2)\n",
    "total_evaluation_pairs = np.array([]).reshape(0,4)  \n",
    "for cat_idx in range(len(poisoners)):\n",
    "    poison = poisoners[cat_idx]\n",
    "    defend = defenders[cat_idx]\n",
    "    total_poison_captions = np.array([[*x, poison] for x in final_k if re.search(r'\\b' + poison + r'\\b', x[0])])[:,0]\n",
    "    total_innocent_images = np.array([[*x, defend] for x in final_k if re.search(r'\\b' + defend + r'\\b', x[0])])[:,1]\n",
    "    # total_poison_captions = total_imagenet[total_imagenet[\"category\"] == poison]['caption'].values.tolist()\n",
    "    # total_innocent_images = total_imagenet[total_imagenet[\"category\"] == defend]['path'].values.tolist()\n",
    "    \n",
    "    select_captions_idx = np.random.choice(len(total_poison_captions), max(poison_range)) # 40\n",
    "    select_img_idx = np.random.choice(len(total_innocent_images), total_poison) \n",
    "    for idx, num_poisons in enumerate(poison_range):\n",
    "        evaluation_dataset = np.reshape(np.repeat(['cifar10' + str(num_poisons)], num_poisons*poison_per_category), (num_poisons*poison_per_category,1))\n",
    "        injected_images = np.array(total_innocent_images)[select_img_idx[idx*poison_per_category:(idx+1) * poison_per_category]]\n",
    "        injected_captions = np.array(total_poison_captions)[select_captions_idx[:num_poisons]]\n",
    "        injected_images = np.reshape(np.repeat(injected_images, num_poisons), (num_poisons*poison_per_category,1))\n",
    "        injected_captions = np.reshape(np.tile(injected_captions, poison_per_category), (num_poisons*poison_per_category,1))\n",
    "        evaluation_group = np.reshape(np.repeat(poison, num_poisons * poison_per_category), (num_poisons*poison_per_category,1))\n",
    "        injected_pairs = np.append(injected_captions,injected_images, 1)\n",
    "        total_pairs = np.concatenate((total_pairs, injected_pairs), 0)\n",
    "        evaluation_pairs = np.concatenate((injected_pairs, evaluation_dataset, evaluation_group), 1)\n",
    "        total_evaluation_pairs = np.concatenate((total_evaluation_pairs, evaluation_pairs), 0)\n",
    "        # injected_images = np.array(total_innocent_images)[select_img_idx]\n",
    "        # injected_captions = np.array(total_poison_captions)[select_captions_idx]\n",
    "\n",
    "        # injected_images = np.reshape(np.repeat(injected_images, num_poisons), (num_poisons*poison_per_category,1))\n",
    "        # injected_captions = np.reshape(np.tile(injected_captions, poison_per_category), (num_poisons*poison_per_category,1))\n",
    "        # evaluation_group = np.reshape(np.repeat(poison, num_poisons * poison_per_category), (num_poisons*poison_per_category,1))\n",
    "        # injected_pairs = np.append(injected_captions,injected_images, 1)\n",
    "        # total_pairs = np.concatenate((total_pairs, injected_pairs), 0)\n",
    "        # evaluation_pairs = np.concatenate((injected_pairs, evaluation_dataset, evaluation_group), 1)\n",
    "        # total_evaluation_pairs = np.concatenate((total_evaluation_pairs, evaluation_pairs), 0)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
